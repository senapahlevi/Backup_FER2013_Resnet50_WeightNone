{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FER2013_Resnet50_weightnone_nodropout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Qn1jsBTIBl0b7myLQxqa8WjCcfbamqM",
      "authorship_tag": "ABX9TyNLkY+b7z40AenKq731S69J"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86nukQOxN7l"
      },
      "source": [
        "Resnet-50 From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p8gxtGy0TWP",
        "outputId": "d71d0a17-2049-4d42-c44e-e7a0c025cd61"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "inputFolder = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth' \n",
        "for root, directories, filenames in os.walk(inputFolder): \n",
        "    for filename in filenames: print(os.path.join(root,filename))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe1.h5\n",
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/scratchcheckpoint/Best_Model_resnet50Scracth_tipe4.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsiscWIMBDX2",
        "outputId": "86d8b0f3-a584-4fb4-85d1-a36677092ba3"
      },
      "source": [
        "%cd /content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "wLMSe510xNCJ",
        "outputId": "3da9f6f5-cb75-4f61-d978-1e7de9a074fc"
      },
      "source": [
        "#Create a directory to save our generated models.\n",
        "\n",
        "#os.mkdir(\"./modelscracth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cf55f19f3613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#os.mkdir(\"./modelscracth\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kluusLxM1B",
        "outputId": "78ad7b63-9c92-42f0-dbc5-4bf69e7e3a15"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:400: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUSF_tAxNMP"
      },
      "source": [
        "#Define the identity block helper function.\n",
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "   \n",
        "    # Second component of main path\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VdYtzhn1F0I"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv2D(F2, (f, f), strides = (1,1), name = conv_name_base + '2b',padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path \n",
        "    X = Conv2D(F3, (1, 1), strides = (1,1), name = conv_name_base + '2c',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH #### \n",
        "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1',padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X_shortcut,X])\n",
        "    X = Activation(\"relu\")(X)\n",
        "        \n",
        "    return X"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-O8ZMx1GAW"
      },
      "source": [
        "def ResNet50(input_shape = (48,48,1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    #X = ZeroPadding2D((1, 1))(X_input)\n",
        "    X = X_input\n",
        "    # Stage 1\n",
        "\n",
        "    X = Conv2D(8, (3, 3), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    # removed maxpool\n",
        "    #X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
        "\n",
        "\n",
        "    # Stage 3 \n",
        "    X = convolutional_block(X, f = 3, filters = [64,64,256], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [64,64,256], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 \n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 \n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL . \n",
        "    X = AveragePooling2D((2,2), name='avg_pool')(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(512, activation = 'relu', name='fc1024' , kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GKsSwtp-GuL"
      },
      "source": [
        "\"\"\"def ResNet50ori(input_shape = (48, 48, 1), classes = 7):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "    \n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50ori')\n",
        "\n",
        "    return model\"\"\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWTDXlyBHM2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d37c6ebb-d855-4e8e-dc6b-5f65e496b4ed"
      },
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        " \n",
        "dataset_path = '/content/drive/MyDrive/FER2013KaggleOri/fer2013/Resnet50Scracth/Scracthfer2013.csv'\n",
        "image_size=(48,48)\n",
        "#batch_size = 64\n",
        "\n",
        "def load_fer2013():\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    data = (data[data['pixels'].notnull()])\n",
        "    pixels = data['pixels'].tolist()\n",
        "    width, height = 48, 48\n",
        "    faces = []\n",
        "    for pixel_sequence in pixels:\n",
        "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "        face = np.asarray(face).reshape(width, height)\n",
        "        face = cv2.resize(face.astype('uint8'),image_size)\n",
        "        faces.append(face.astype('float32'))\n",
        "    faces = np.asarray(faces)\n",
        "    faces = np.expand_dims(faces, -1)\n",
        "    emotions = (data['emotion'])#.values\n",
        "    return faces, emotions\n",
        " \n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        " \n",
        "faces, emotions = load_fer2013()\n",
        "faces = preprocess_input(faces)\n",
        "#xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
        "#Data Augumentation\n",
        "data_generator = ImageDataGenerator(\n",
        "                        rotation_range=10,\n",
        "                        shear_range = 10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "\"\"\"data_generator = ImageDataGenerator( )\n",
        "\"\"\""
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_generator = ImageDataGenerator( )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWLhavr-rSF5"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(faces, emotions, test_size=0.1, train_size=0.9)\n",
        "x_train, x_val, y_train, y_val = train_test_split(xtrain, ytrain, test_size=0.1, train_size=0.9)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGhnYFXgaqL9",
        "outputId": "81052a03-7965-4c27-e619-9d4fdd05c9c7"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (y_train.shape)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3230, 48, 48, 1)\n",
            "(3230,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(32298, 48, 48, 1)\n",
            "(29068,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9Q-TegBR26"
      },
      "source": [
        "#hyperparameter and callback\n",
        "batch_size = 64\n",
        "num_epochs = 60\n",
        "input_shape = (48, 48, 1)\n",
        "num_classes = 7\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGsscQRJBR-h"
      },
      "source": [
        "#Compile the model.\n",
        "\n",
        "\n",
        "from keras.optimizers import Adam, SGD\n",
        "model = ResNet50(input_shape = (48, 48, 1), classes = 7)\n",
        "optimizer = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-7)\n",
        "model.compile(optimizer= optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rodttDWeT2yP"
      },
      "source": [
        "#kita mau save model callbacks\n",
        "import os\n",
        "try:\n",
        "  os.mkdir('scratchcheckpoint')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV29sTjET28U"
      },
      "source": [
        "file_name = 'Best_Model_resnet50Scracth_sena1.h5'\n",
        "\n",
        "checkpoint_path = os.path.join('checkpoint',file_name)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_S6wUaPT3Jx"
      },
      "source": [
        "call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                               monitor='val_accuracy',\n",
        "                                               verbose=1,\n",
        "                                               save_freq='epoch',\n",
        "                                               save_best_only=True,\n",
        "                                               save_weights_only=False,\n",
        "                                               mode='max')"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy53DHMGB-Mr",
        "outputId": "6386cbc4-766b-4812-806a-5d3f483582e2"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 46, 46, 8)    80          input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 46, 46, 8)    32          conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 46, 46, 8)    0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 46, 46, 32)   288         activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 46, 46, 32)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 46, 46, 128)  1152        activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 46, 46, 128)  512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_96 (Add)                    (None, 46, 46, 128)  0           bn2a_branch1[0][0]               \n",
            "                                                                 bn2a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 46, 46, 128)  0           add_96[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 46, 46, 32)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_97 (Add)                    (None, 46, 46, 128)  0           activation_297[0][0]             \n",
            "                                                                 bn2b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 46, 46, 128)  0           add_97[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 46, 46, 32)   4128        activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 46, 46, 32)   9248        activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 46, 46, 32)   128         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 46, 46, 32)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 46, 46, 128)  4224        activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 46, 46, 128)  512         res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_98 (Add)                    (None, 46, 46, 128)  0           activation_300[0][0]             \n",
            "                                                                 bn2c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 46, 46, 128)  0           add_98[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 23, 23, 64)   8256        activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 23, 23, 64)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 23, 23, 256)  33024       activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_99 (Add)                    (None, 23, 23, 256)  0           bn3a_branch1[0][0]               \n",
            "                                                                 bn3a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 23, 23, 256)  0           add_99[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 23, 23, 64)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_100 (Add)                   (None, 23, 23, 256)  0           activation_306[0][0]             \n",
            "                                                                 bn3b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, 23, 23, 256)  0           add_100[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, 23, 23, 64)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_101 (Add)                   (None, 23, 23, 256)  0           activation_309[0][0]             \n",
            "                                                                 bn3c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 23, 23, 256)  0           add_101[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 23, 23, 64)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_102 (Add)                   (None, 23, 23, 256)  0           activation_312[0][0]             \n",
            "                                                                 bn3d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 23, 23, 256)  0           add_102[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 12, 12, 128)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_103 (Add)                   (None, 12, 12, 512)  0           bn4a_branch1[0][0]               \n",
            "                                                                 bn4a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 12, 12, 512)  0           add_103[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 12, 12, 128)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_104 (Add)                   (None, 12, 12, 512)  0           activation_318[0][0]             \n",
            "                                                                 bn4b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 12, 12, 512)  0           add_104[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 12, 12, 128)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_105 (Add)                   (None, 12, 12, 512)  0           activation_321[0][0]             \n",
            "                                                                 bn4c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 12, 12, 512)  0           add_105[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 12, 12, 128)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_106 (Add)                   (None, 12, 12, 512)  0           activation_324[0][0]             \n",
            "                                                                 bn4d_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 12, 12, 512)  0           add_106[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 12, 12, 128)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_107 (Add)                   (None, 12, 12, 512)  0           activation_327[0][0]             \n",
            "                                                                 bn4e_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 12, 12, 512)  0           add_107[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 12, 12, 128)  65664       activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_331[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 12, 12, 128)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_332[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_108 (Add)                   (None, 12, 12, 512)  0           activation_330[0][0]             \n",
            "                                                                 bn4f_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 12, 12, 512)  0           add_108[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 6, 6, 256)    131328      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 6, 6, 256)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 6, 6, 1024)   525312      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_335[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 6, 6, 1024)   4096        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_109 (Add)                   (None, 6, 6, 1024)   0           bn5a_branch1[0][0]               \n",
            "                                                                 bn5a_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 6, 6, 1024)   0           add_109[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 6, 6, 256)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_110 (Add)                   (None, 6, 6, 1024)   0           activation_336[0][0]             \n",
            "                                                                 bn5b_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 6, 6, 1024)   0           add_110[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 6, 6, 256)    262400      activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 6, 6, 256)    590080      activation_340[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 6, 6, 256)    1024        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 6, 6, 256)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 6, 6, 1024)   263168      activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 6, 6, 1024)   4096        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_111 (Add)                   (None, 6, 6, 1024)   0           activation_339[0][0]             \n",
            "                                                                 bn5c_branch2c[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 6, 6, 1024)   0           add_111[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 3, 3, 1024)   0           activation_342[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 9216)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "fc1024 (Dense)                  (None, 512)          4719104     flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc7 (Dense)                     (None, 7)            3591        fc1024[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 10,646,583\n",
            "Trainable params: 10,620,071\n",
            "Non-trainable params: 26,512\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgxCecVwCGEr",
        "outputId": "8988e6bf-b434-4650-c46f-22f92303943d"
      },
      "source": [
        "\"\"\"history = model.fit(data_generator.flow(xtrain, ytrain,),\n",
        "                        steps_per_epoch=len(xtrain) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1,callbacks=call_back,\n",
        "                        validation_data= (xtest,ytest))\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "448/448 [==============================] - 65s 122ms/step - loss: 2.2711 - accuracy: 0.2151 - val_loss: 1.8425 - val_accuracy: 0.2538\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.25383, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.8064 - accuracy: 0.2511 - val_loss: 1.8161 - val_accuracy: 0.2594\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.25383 to 0.25940, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 3/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.7689 - accuracy: 0.2632 - val_loss: 1.7616 - val_accuracy: 0.2795\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.25940 to 0.27947, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 4/50\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.7297 - accuracy: 0.3022 - val_loss: 1.7276 - val_accuracy: 0.2990\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.27947 to 0.29897, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 5/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.6804 - accuracy: 0.3269 - val_loss: 1.6247 - val_accuracy: 0.3504\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.29897 to 0.35038, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 6/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.6096 - accuracy: 0.3661 - val_loss: 1.5590 - val_accuracy: 0.3823\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.35038 to 0.38228, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 7/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.5340 - accuracy: 0.4051 - val_loss: 1.5257 - val_accuracy: 0.4087\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.38228 to 0.40875, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 8/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.5127 - accuracy: 0.4046 - val_loss: 1.5014 - val_accuracy: 0.4139\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.40875 to 0.41390, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 9/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4779 - accuracy: 0.4241 - val_loss: 1.4280 - val_accuracy: 0.4503\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.41390 to 0.45026, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 10/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4282 - accuracy: 0.4475 - val_loss: 1.4991 - val_accuracy: 0.4154\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.45026\n",
            "Epoch 11/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.4105 - accuracy: 0.4555 - val_loss: 1.3838 - val_accuracy: 0.4620\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.45026 to 0.46197, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 12/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.3500 - accuracy: 0.4850 - val_loss: 1.3392 - val_accuracy: 0.4799\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.46197 to 0.47994, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 13/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.3333 - accuracy: 0.4895 - val_loss: 1.3158 - val_accuracy: 0.4946\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.47994 to 0.49457, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 14/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.2905 - accuracy: 0.5087 - val_loss: 1.3923 - val_accuracy: 0.4912\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.49457\n",
            "Epoch 15/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2800 - accuracy: 0.5112 - val_loss: 1.2229 - val_accuracy: 0.5344\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.49457 to 0.53441, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 16/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.2456 - accuracy: 0.5286 - val_loss: 1.2321 - val_accuracy: 0.5258\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.53441\n",
            "Epoch 17/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2397 - accuracy: 0.5268 - val_loss: 1.2038 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.53441 to 0.53845, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 18/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.2112 - accuracy: 0.5434 - val_loss: 1.2470 - val_accuracy: 0.5208\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.53845\n",
            "Epoch 19/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.1876 - accuracy: 0.5505 - val_loss: 1.2147 - val_accuracy: 0.5336\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.53845\n",
            "Epoch 20/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 1.1875 - accuracy: 0.5495 - val_loss: 1.1693 - val_accuracy: 0.5511\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.53845 to 0.55113, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 21/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 1.1622 - accuracy: 0.5580 - val_loss: 1.2089 - val_accuracy: 0.5344\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.55113\n",
            "Epoch 22/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 1.1420 - accuracy: 0.5658 - val_loss: 1.1683 - val_accuracy: 0.5574\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.55113 to 0.55740, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 23/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 1.1426 - accuracy: 0.5670 - val_loss: 1.1895 - val_accuracy: 0.5475\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.55740\n",
            "Epoch 24/50\n",
            "448/448 [==============================] - 57s 126ms/step - loss: 1.1447 - accuracy: 0.5654 - val_loss: 1.1481 - val_accuracy: 0.5698\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.55740 to 0.56980, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 25/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0988 - accuracy: 0.5806 - val_loss: 1.0838 - val_accuracy: 0.5938\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.56980 to 0.59376, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 26/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.0941 - accuracy: 0.5851 - val_loss: 1.2003 - val_accuracy: 0.5529\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.59376\n",
            "Epoch 27/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0957 - accuracy: 0.5909 - val_loss: 1.1363 - val_accuracy: 0.5758\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.59376\n",
            "Epoch 28/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 1.0562 - accuracy: 0.6027 - val_loss: 1.1244 - val_accuracy: 0.5738\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.59376\n",
            "Epoch 29/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0445 - accuracy: 0.6041 - val_loss: 1.0976 - val_accuracy: 0.5861\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.59376\n",
            "Epoch 30/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0413 - accuracy: 0.5992 - val_loss: 1.1102 - val_accuracy: 0.5867\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.59376\n",
            "Epoch 31/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 1.0303 - accuracy: 0.6060 - val_loss: 1.0553 - val_accuracy: 0.6056\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.59376 to 0.60560, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 32/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0454 - accuracy: 0.6025 - val_loss: 1.0681 - val_accuracy: 0.5988\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.60560\n",
            "Epoch 33/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 1.0070 - accuracy: 0.6213 - val_loss: 1.0881 - val_accuracy: 0.5949\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.60560\n",
            "Epoch 34/50\n",
            "448/448 [==============================] - 57s 127ms/step - loss: 1.0123 - accuracy: 0.6159 - val_loss: 1.1018 - val_accuracy: 0.5897\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.60560\n",
            "Epoch 35/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 0.9944 - accuracy: 0.6208 - val_loss: 1.0713 - val_accuracy: 0.5999\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.60560\n",
            "Epoch 36/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 1.0049 - accuracy: 0.6201 - val_loss: 1.0473 - val_accuracy: 0.6127\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.60560 to 0.61271, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 37/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9791 - accuracy: 0.6334 - val_loss: 1.0589 - val_accuracy: 0.6043\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.61271\n",
            "Epoch 38/50\n",
            "448/448 [==============================] - 56s 125ms/step - loss: 0.9641 - accuracy: 0.6281 - val_loss: 1.0680 - val_accuracy: 0.5972\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.61271\n",
            "Epoch 39/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9775 - accuracy: 0.6277 - val_loss: 1.2166 - val_accuracy: 0.5575\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.61271\n",
            "Epoch 40/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 0.9695 - accuracy: 0.6381 - val_loss: 1.0728 - val_accuracy: 0.5947\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.61271\n",
            "Epoch 41/50\n",
            "448/448 [==============================] - 51s 113ms/step - loss: 0.9418 - accuracy: 0.6410 - val_loss: 1.0668 - val_accuracy: 0.5978\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.61271\n",
            "Epoch 42/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9483 - accuracy: 0.6383 - val_loss: 1.0436 - val_accuracy: 0.6160\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.61271 to 0.61605, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 43/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 0.9589 - accuracy: 0.6440 - val_loss: 1.0460 - val_accuracy: 0.6101\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.61605\n",
            "Epoch 44/50\n",
            "448/448 [==============================] - 52s 116ms/step - loss: 0.9422 - accuracy: 0.6480 - val_loss: 1.0838 - val_accuracy: 0.5991\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.61605\n",
            "Epoch 45/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 0.9410 - accuracy: 0.6449 - val_loss: 1.0646 - val_accuracy: 0.5995\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.61605\n",
            "Epoch 46/50\n",
            "448/448 [==============================] - 56s 124ms/step - loss: 0.9130 - accuracy: 0.6571 - val_loss: 1.0363 - val_accuracy: 0.6148\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.61605\n",
            "Epoch 47/50\n",
            "448/448 [==============================] - 51s 115ms/step - loss: 0.9051 - accuracy: 0.6632 - val_loss: 1.0098 - val_accuracy: 0.6296\n",
            "\n",
            "Epoch 00047: val_accuracy improved from 0.61605 to 0.62956, saving model to checkpoint/Best_Model_resnet50Scracth_tipe6.h5\n",
            "Epoch 48/50\n",
            "448/448 [==============================] - 56s 126ms/step - loss: 0.9064 - accuracy: 0.6556 - val_loss: 1.0776 - val_accuracy: 0.6002\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.62956\n",
            "Epoch 49/50\n",
            "448/448 [==============================] - 51s 114ms/step - loss: 0.9066 - accuracy: 0.6624 - val_loss: 1.0612 - val_accuracy: 0.6158\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.62956\n",
            "Epoch 50/50\n",
            "448/448 [==============================] - 52s 115ms/step - loss: 0.9066 - accuracy: 0.6581 - val_loss: 1.0227 - val_accuracy: 0.6211\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.62956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2muXWns0sJSH",
        "outputId": "cfced0bf-18c2-4af7-ab90-71e65f6dbb94"
      },
      "source": [
        "history = model.fit(\n",
        "    data_generator.flow(xtrain, ytrain,),\n",
        "    steps_per_epoch=len(xtrain) / batch_size,\n",
        "    epochs=num_epochs, \n",
        "    verbose=1,\n",
        "    callbacks=call_back,\n",
        "    validation_data= (x_val,y_val))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "504/504 [==============================] - 94s 159ms/step - loss: 14.7872 - accuracy: 0.2306 - val_loss: 1.7755 - val_accuracy: 0.2632\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.26316, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/60\n",
            "504/504 [==============================] - 76s 151ms/step - loss: 1.7940 - accuracy: 0.2537 - val_loss: 1.7703 - val_accuracy: 0.2749\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.26316 to 0.27492, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 3/60\n",
            "504/504 [==============================] - 76s 151ms/step - loss: 1.7600 - accuracy: 0.2644 - val_loss: 1.7162 - val_accuracy: 0.3080\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.27492 to 0.30805, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 4/60\n",
            "504/504 [==============================] - 76s 151ms/step - loss: 1.7282 - accuracy: 0.2856 - val_loss: 1.7011 - val_accuracy: 0.3161\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.30805 to 0.31610, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 5/60\n",
            "504/504 [==============================] - 76s 151ms/step - loss: 1.7139 - accuracy: 0.3010 - val_loss: 1.7128 - val_accuracy: 0.2957\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.31610\n",
            "Epoch 6/60\n",
            "504/504 [==============================] - 76s 150ms/step - loss: 1.6924 - accuracy: 0.3222 - val_loss: 1.6896 - val_accuracy: 0.3628\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.31610 to 0.36285, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 7/60\n",
            "504/504 [==============================] - 76s 151ms/step - loss: 1.6744 - accuracy: 0.3281 - val_loss: 1.6976 - val_accuracy: 0.3279\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.36285\n",
            "Epoch 8/60\n",
            "504/504 [==============================] - 76s 150ms/step - loss: 1.6825 - accuracy: 0.3240 - val_loss: 1.8170 - val_accuracy: 0.2938\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.36285\n",
            "Epoch 9/60\n",
            "504/504 [==============================] - 76s 150ms/step - loss: 1.6088 - accuracy: 0.3612 - val_loss: 1.6700 - val_accuracy: 0.3031\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.36285\n",
            "Epoch 10/60\n",
            "504/504 [==============================] - 76s 150ms/step - loss: 1.5761 - accuracy: 0.3793 - val_loss: 1.5126 - val_accuracy: 0.4087\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.36285 to 0.40867, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 11/60\n",
            "504/504 [==============================] - 76s 151ms/step - loss: 1.5395 - accuracy: 0.3921 - val_loss: 1.5300 - val_accuracy: 0.4065\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.40867\n",
            "Epoch 12/60\n",
            "504/504 [==============================] - 77s 154ms/step - loss: 1.5315 - accuracy: 0.3930 - val_loss: 1.4482 - val_accuracy: 0.4245\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.40867 to 0.42446, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 13/60\n",
            "504/504 [==============================] - 76s 150ms/step - loss: 1.4715 - accuracy: 0.4267 - val_loss: 1.4628 - val_accuracy: 0.4266\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.42446 to 0.42663, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 14/60\n",
            "504/504 [==============================] - 76s 151ms/step - loss: 1.4135 - accuracy: 0.4544 - val_loss: 1.3680 - val_accuracy: 0.4827\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.42663 to 0.48266, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 15/60\n",
            "504/504 [==============================] - 76s 151ms/step - loss: 1.4011 - accuracy: 0.4520 - val_loss: 1.4019 - val_accuracy: 0.4483\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.48266\n",
            "Epoch 16/60\n",
            "504/504 [==============================] - 76s 151ms/step - loss: 1.3813 - accuracy: 0.4589 - val_loss: 1.6888 - val_accuracy: 0.4594\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.48266\n",
            "Epoch 17/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.3555 - accuracy: 0.4695 - val_loss: 1.2954 - val_accuracy: 0.4994\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.48266 to 0.49938, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 18/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.3337 - accuracy: 0.4847 - val_loss: 1.3990 - val_accuracy: 0.4848\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.49938\n",
            "Epoch 19/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.3156 - accuracy: 0.4961 - val_loss: 1.3999 - val_accuracy: 0.4743\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.49938\n",
            "Epoch 20/60\n",
            "504/504 [==============================] - 78s 155ms/step - loss: 1.2906 - accuracy: 0.5035 - val_loss: 1.3253 - val_accuracy: 0.4755\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.49938\n",
            "Epoch 21/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.2708 - accuracy: 0.5127 - val_loss: 1.3562 - val_accuracy: 0.4916\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.49938\n",
            "Epoch 22/60\n",
            "504/504 [==============================] - 76s 152ms/step - loss: 1.2830 - accuracy: 0.4977 - val_loss: 1.2250 - val_accuracy: 0.5297\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.49938 to 0.52972, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 23/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.2505 - accuracy: 0.5139 - val_loss: 1.2185 - val_accuracy: 0.5341\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.52972 to 0.53406, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 24/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.2446 - accuracy: 0.5159 - val_loss: 1.2100 - val_accuracy: 0.5288\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.53406\n",
            "Epoch 25/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.2308 - accuracy: 0.5205 - val_loss: 1.1627 - val_accuracy: 0.5511\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.53406 to 0.55108, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 26/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.2326 - accuracy: 0.5261 - val_loss: 1.2850 - val_accuracy: 0.5155\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.55108\n",
            "Epoch 27/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.2131 - accuracy: 0.5296 - val_loss: 1.1532 - val_accuracy: 0.5452\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.55108\n",
            "Epoch 28/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.2032 - accuracy: 0.5332 - val_loss: 1.1772 - val_accuracy: 0.5594\n",
            "\n",
            "Epoch 00028: val_accuracy improved from 0.55108 to 0.55944, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 29/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.1873 - accuracy: 0.5471 - val_loss: 1.1170 - val_accuracy: 0.5755\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.55944 to 0.57554, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 30/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.2022 - accuracy: 0.5386 - val_loss: 1.4542 - val_accuracy: 0.4672\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.57554\n",
            "Epoch 31/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.2007 - accuracy: 0.5335 - val_loss: 1.1005 - val_accuracy: 0.5647\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.57554\n",
            "Epoch 32/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.1652 - accuracy: 0.5558 - val_loss: 1.1069 - val_accuracy: 0.5820\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.57554 to 0.58204, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 33/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.1262 - accuracy: 0.5723 - val_loss: 1.1364 - val_accuracy: 0.5625\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.58204\n",
            "Epoch 34/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.1518 - accuracy: 0.5552 - val_loss: 1.1718 - val_accuracy: 0.5449\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.58204\n",
            "Epoch 35/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.1392 - accuracy: 0.5559 - val_loss: 1.1467 - val_accuracy: 0.5480\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.58204\n",
            "Epoch 36/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.1438 - accuracy: 0.5565 - val_loss: 1.0694 - val_accuracy: 0.5907\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.58204 to 0.59071, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 37/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.1299 - accuracy: 0.5654 - val_loss: 1.1866 - val_accuracy: 0.5591\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.59071\n",
            "Epoch 38/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.1211 - accuracy: 0.5669 - val_loss: 1.0821 - val_accuracy: 0.5759\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.59071\n",
            "Epoch 39/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.1487 - accuracy: 0.5606 - val_loss: 1.1469 - val_accuracy: 0.5777\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.59071\n",
            "Epoch 40/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.1313 - accuracy: 0.5667 - val_loss: 1.1673 - val_accuracy: 0.5591\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.59071\n",
            "Epoch 41/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.1137 - accuracy: 0.5750 - val_loss: 1.0490 - val_accuracy: 0.5947\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.59071 to 0.59474, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 42/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0843 - accuracy: 0.5879 - val_loss: 1.0697 - val_accuracy: 0.5985\n",
            "\n",
            "Epoch 00042: val_accuracy improved from 0.59474 to 0.59845, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 43/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.0819 - accuracy: 0.5803 - val_loss: 1.1311 - val_accuracy: 0.5622\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.59845\n",
            "Epoch 44/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.1061 - accuracy: 0.5817 - val_loss: 1.0819 - val_accuracy: 0.5820\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.59845\n",
            "Epoch 45/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.1054 - accuracy: 0.5827 - val_loss: 0.9941 - val_accuracy: 0.6118\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.59845 to 0.61176, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 46/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0882 - accuracy: 0.5903 - val_loss: 1.0334 - val_accuracy: 0.6028\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.61176\n",
            "Epoch 47/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0817 - accuracy: 0.5888 - val_loss: 1.0271 - val_accuracy: 0.6115\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.61176\n",
            "Epoch 48/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0838 - accuracy: 0.5905 - val_loss: 1.1072 - val_accuracy: 0.5861\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.61176\n",
            "Epoch 49/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0864 - accuracy: 0.5864 - val_loss: 0.9748 - val_accuracy: 0.6282\n",
            "\n",
            "Epoch 00049: val_accuracy improved from 0.61176 to 0.62817, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 50/60\n",
            "504/504 [==============================] - 79s 156ms/step - loss: 1.0562 - accuracy: 0.5985 - val_loss: 0.9891 - val_accuracy: 0.6316\n",
            "\n",
            "Epoch 00050: val_accuracy improved from 0.62817 to 0.63158, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 51/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0597 - accuracy: 0.5973 - val_loss: 0.9955 - val_accuracy: 0.6201\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.63158\n",
            "Epoch 52/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.0455 - accuracy: 0.6043 - val_loss: 1.0670 - val_accuracy: 0.5954\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.63158\n",
            "Epoch 53/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0913 - accuracy: 0.5874 - val_loss: 0.9999 - val_accuracy: 0.6341\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.63158 to 0.63406, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 54/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0424 - accuracy: 0.6054 - val_loss: 1.0319 - val_accuracy: 0.6053\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.63406\n",
            "Epoch 55/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0498 - accuracy: 0.6025 - val_loss: 0.9792 - val_accuracy: 0.6266\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.63406\n",
            "Epoch 56/60\n",
            "504/504 [==============================] - 77s 152ms/step - loss: 1.0403 - accuracy: 0.6071 - val_loss: 0.9550 - val_accuracy: 0.6353\n",
            "\n",
            "Epoch 00056: val_accuracy improved from 0.63406 to 0.63529, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n",
            "Epoch 57/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0467 - accuracy: 0.5964 - val_loss: 0.9858 - val_accuracy: 0.6285\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.63529\n",
            "Epoch 58/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0431 - accuracy: 0.6039 - val_loss: 1.0168 - val_accuracy: 0.6111\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.63529\n",
            "Epoch 59/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0328 - accuracy: 0.6153 - val_loss: 0.9946 - val_accuracy: 0.6279\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.63529\n",
            "Epoch 60/60\n",
            "504/504 [==============================] - 77s 153ms/step - loss: 1.0384 - accuracy: 0.6091 - val_loss: 0.9617 - val_accuracy: 0.6368\n",
            "\n",
            "Epoch 00060: val_accuracy improved from 0.63529 to 0.63684, saving model to checkpoint/Best_Model_resnet50Scracth_sena1.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "GaXUP-8fDWRN",
        "outputId": "e502dc5c-7115-407b-f894-0067d6644f95"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "\n",
        "#gffhgffkjkjdskjjkjkjkj\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "num_epochs = range(len(accuracy))\n",
        "plt.plot(num_epochs, accuracy, 'r', label='Training acc')\n",
        "plt.plot(num_epochs, val_accuracy, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(num_epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(num_epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydZ3hU1daA30XoRXoHAZUiIDViQREUrygCYqVYwAoWEHsFLuq1fqLeiwULFlQUC6KCCoKiWCCooCAIUpQYEOmdlPX9WDNhkswkk5BJgfU+z3lmzj5771kzgbPO3quJquI4juM4mSlR2AI4juM4RRNXEI7jOE5YXEE4juM4YXEF4TiO44TFFYTjOI4TFlcQjuM4TlhcQThRIyLTReSy/O5bmIjIahHpHoN5VUSOCrx/VkTujaZvHj5noIh8llc5HSc7xOMgDm5EZEfIaXlgL5AaOL9GVV8veKmKDiKyGrhSVWfm87wKNFXVFfnVV0QaA6uAUqqakh9yOk52lCxsAZzYoqoVg++zuxmKSEm/6ThFBf/3WDTwLaZDFBHpKiJrReR2EVkHTBCRqiLykYhsEJHNgfcNQsZ8ISJXBt4PEpGvReSxQN9VInJmHvs2EZE5IrJdRGaKyDgRmRhB7mhkvE9E5gbm+0xEaoRcv0RE1ojIRhG5O5vf5zgRWScicSFtfUVkUeB9JxH5VkS2iEiSiPxPREpHmOtlEbk/5PzWwJi/ROTyTH17isiPIrJNRP4UkdEhl+cEXreIyA4ROSH424aMP1FE5ovI1sDridH+Nrn8nauJyITAd9gsIlNCrvURkZ8C3+F3EekRaM+wnScio4N/ZxFpHNhqu0JE/gBmBdonB/4OWwP/RlqFjC8nIv8X+HtuDfwbKyciH4vIDZm+zyIR6RvuuzqRcQVxaFMHqAY0Aq7G/j1MCJwfDuwG/pfN+OOAZUAN4BHgRRGRPPR9A5gHVAdGA5dk85nRyDgAGAzUAkoDtwCISEvgmcD89QKf14AwqOr3wE7g1EzzvhF4nwqMCHyfE4DTgGuzkZuADD0C8pwONAUy2z92ApcCVYCewFAROSdwrUvgtYqqVlTVbzPNXQ34GHgq8N0eBz4WkeqZvkOW3yYMOf3Or2Fblq0Cc40NyNAJeBW4NfAdugCrI/0eYTgFOBo4I3A+HfudagE/AKFboo8BHYETsX/HtwFpwCvAxcFOItIWqI/9Nk5uUFU/DpED+4/aPfC+K7APKJtN/3bA5pDzL7AtKoBBwIqQa+UBBerkpi9280kByodcnwhMjPI7hZPxnpDza4FPAu9HApNCrlUI/AbdI8x9P/BS4H0l7ObdKELfG4H3Q84VOCrw/mXg/sD7l4CHQvo1C+0bZt4ngLGB940DfUuGXB8EfB14fwkwL9P4b4FBOf02ufmdgbrYjbhqmH7PBeXN7t9f4Hx08O8c8t2OyEaGKoE+lTEFthtoG6ZfWWAzZtcBUyRPF/T/t4Ph8BXEoc0GVd0TPBGR8iLyXGDJvg3b0qgSus2SiXXBN6q6K/C2Yi771gM2hbQB/BlJ4ChlXBfyfleITPVC51bVncDGSJ+FrRbOFZEywLnAD6q6JiBHs8C2y7qAHP/BVhM5kUEGYE2m73eciMwObO1sBYZEOW9w7jWZ2tZgT89BIv02Gcjhd26I/c02hxnaEPg9SnnDkf7biEiciDwU2Kbaxv6VSI3AUTbcZwX+Tb8FXCwiJYD+2IrHySWuIA5tMruw3Qw0B45T1cPYv6URadsoP0gCqolI+ZC2htn0PxAZk0LnDnxm9UidVXUJdoM9k4zbS2BbVUuxp9TDgLvyIgO2ggrlDWAq0FBVKwPPhsybk8vhX9iWUCiHA4lRyJWZ7H7nP7G/WZUw4/4Ejoww505s9RikTpg+od9xANAH24arjK0ygjL8A+zJ5rNeAQZiW3+7NNN2nBMdriCcUCphy/Ytgf3sUbH+wMATeQIwWkRKi8gJQK8YyfgOcLaInBQwKI8h5/8DbwDDsRvk5ExybAN2iEgLYGiUMrwNDBKRlgEFlVn+StjT+Z7Afv6AkGsbsK2dIyLMPQ1oJiIDRKSkiFwEtAQ+ilK2zHKE/Z1VNQmzDTwdMGaXEpGgAnkRGCwip4lICRGpH/h9AH4C+gX6xwPnRyHDXmyVVx5bpQVlSMO26x4XkXqB1cYJgdUeAYWQBvwfvnrIM64gnFCeAMphT2ffAZ8U0OcOxAy9G7F9/7ewG0M48iyjqi4GrsNu+knYPvXaHIa9iRlOZ6nqPyHtt2A37+3A8wGZo5FheuA7zAJWBF5DuRYYIyLbMZvJ2yFjdwEPAHPFvKeOzzT3RuBs7Ol/I2a0PTuT3NGS0+98CZCMraL+xmwwqOo8zAg+FtgKfMn+Vc292BP/ZuDfZFyRheNVbAWXCCwJyBHKLcDPwHxgE/AwGe9prwLHYDYtJw94oJxT5BCRt4ClqhrzFYxz8CIilwJXq+pJhS1LccVXEE6hIyLHisiRgS2JHti+85ScxjlOJALbd9cC4wtbluKMKwinKFAHc8HcgfnwD1XVHwtVIqfYIiJnYPaa9eS8jeVkg28xOY7jOGHxFYTjOI4Tlpgm6wvsJz8JxAEvqOpDYfpciEVUKrBQVQcE2lMxDwWAP1S1d3afVaNGDW3cuHH+Ce84jnMIsGDBgn9UtWa4azFTEIGIy3FYzpm1wHwRmRoIPgr2aQrcCXRW1c0iUitkit2q2i7az2vcuDEJCQn5JL3jOM6hgYhkjr5PJ5ZbTJ2w/DsrVXUfMAnzTgnlKmBcMGRfVf+OoTyO4zhOLoilgqhPxpwza8mYEwYsUVkzsfTD3wXTAgcoKyIJgfZzcBzHcQqUwi4YVBJL5dsVS7s8R0SOUdUtWNbMRBE5ApglIj+raobEXCJyNZammsMPz5zSxnEcxzkQYqkgEsmYlKwBWZOGrQW+V9VkYJWI/IYpjPmqmgigqitF5AugPZkyN6rqeAKBMPHx8Vn8dZOTk1m7di179uzJfMkpIpQtW5YGDRpQqlSpwhbFcZxMxFJBzAeaikgTTDH0I2PiMbBo2f5YNbMa2JbTShGpimVg3Bto74wVmckVa9eupVKlSjRu3JjIdWycwkJV2bhxI2vXrqVJkyaFLY7jOJmImQ1CrZ7s9cCnwK/A26q6WETGiEjQZfVTYKOILAFmA7cGEo4dDSSIyMJA+0Oh3k/RsmfPHqpXr+7KoYgiIlSvXt1XeI5TRImpDUJVp2EpiEPbRoa8V+CmwBHa5xssC+MB48qhaON/H8cpungkteM4TjFm6lR45ZXYzO0KIoZs3LiRdu3a0a5dO+rUqUP9+vXTz/ft25ft2ISEBIYNG5bjZ5x44on5Ja7jOFGQkgKpqXkbO3cuXHwx/PJL/sgybhz07Qvjx+ddpuwobDfXg5rq1avz008/ATB69GgqVqzILbfckn49JSWFkiXD/wni4+OJj4/P8TO++eab/BHWcZyo6NYNjjoKJkzI3bjXXoMrr4R9++Dtt2HUKLjtNsiLA19aGtx+Ozz2GPTqBW++CXGRKscfAL6CKGAGDRrEkCFDOO6447jtttuYN28eJ5xwAu3bt+fEE09k2bJlAHzxxRecffbZgCmXyy+/nK5du3LEEUfw1FNPpc9XsWLF9P5du3bl/PPPp0WLFgwcOJBgpt5p06bRokULOnbsyLBhw9LnDWX16tWcfPLJdOjQgQ4dOmRQPA8//DDHHHMMbdu25Y477gBgxYoVdO/enbZt29KhQwd+//1A6tQ7TuxJSYFZs2DoUDj+eFi8OPdzrF8PX39tN+StW6Mbk5YG99wDl14KJ50Ev/0G551nbccfD4sW5U6GPXugf39TDtddB++/DxUq5P67RMOhs4K48UYIPM3nG+3awRNP5HrY2rVr+eabb4iLi2Pbtm189dVXlCxZkpkzZ3LXXXfx7rvvZhmzdOlSZs+ezfbt22nevDlDhw7NEjvw448/snjxYurVq0fnzp2ZO3cu8fHxXHPNNcyZM4cmTZrQv3//sDLVqlWLGTNmULZsWZYvX07//v1JSEhg+vTpfPDBB3z//feUL1+eTZs2ATBw4EDuuOMO+vbty549e0hLS8v17+A4sUYVZs+GyZPh3XdhwwYoXx7KlIEePeCbb6Bhw5znCTIrUCB271547z0YPDj7/rt2waBB9vlXXglPP20rhjffhAsuMGUVHw/33gt33ZXzKmDTJujTx5TUo4/CzTdDLP08Dh0FUYS44IILiAv8S9i6dSuXXXYZy5cvR0RITk4OO6Znz56UKVOGMmXKUKtWLdavX0+DBg0y9OnUqVN6W7t27Vi9ejUVK1bkiCOOSI8z6N+/P+PHZy2ylZyczPXXX89PP/1EXFwcv/32GwAzZ85k8ODBlC9fHoBq1aqxfft2EhMT6du3L2DBbo5TFBk/HoYMsSfss8+G88+Hs86C5cuhSxc480z46iuoWjW6+WbOhCpVoHp1eP317BXE+vW2/ZOQYE/7N92U8WZ+7rkmw7BhMHKkKa3bbos83759cNppsGQJTJoEF10UncwHwqGjIPLwpB8rKoSsB++99166devG+++/z+rVq+natWvYMWXKlEl/HxcXR0pKSp76RGLs2LHUrl2bhQsXkpaW5jd956Bg6lRo2tQ2DwLPOAC0bWtbMz162BP5Z59BTv/kVWHGDDj1VGjdGu67D/76C+rVC9//xhvNGD1lCvSOUKygRg144w3YscPmu/jiyPONHWvf4733zDBdELgNopDZunUr9etbDsOXX3453+dv3rw5K1euZPXq1QC89dZbEeWoW7cuJUqU4LXXXiM14BJx+umnM2HCBHbt2gXApk2bqFSpEg0aNGDKFCsbvXfv3vTrjlNUSE21rZhu3TIqhyCnnmqG46++goEDc/YCWrEC/vwTune3/qr2JB+O5cvNED1sWGTlEMrYsZCcHHkFsWYNjBljyqyglAO4gih0brvtNu68807at2+fqyf+aClXrhxPP/00PXr0oGPHjlSqVInKlStn6Xfttdfyyiuv0LZtW5YuXZq+yunRowe9e/cmPj6edu3a8dhjjwHw2muv8dRTT9GmTRtOPPFE1q1bl++yO86BsGgRbNsGp5wSuc9FF9nN+b33YPhwu+lHYuZMe+3eHZo1M9vBxInh+z70EJQuDSNGRCfrkUfCrbfattVXX2W9HvR4D/FPKRhU9aA4OnbsqJlZsmRJlrZDke3bt6uqalpamg4dOlQff/zxQpYoI/53cmLB2LGqoPrnnzn3veUW6/vWW5H7nHuu6uGHq6alZZw/8z/fNWtUS5ZUveGG3Mm7c6dqw4aqbduqpqTsb//gA/uchx/O3XzRAiRohPuqryAOAZ5//nnatWtHq1at2Lp1K9dcc01hi+Q4MWfOHDjiCMjkyxGWhx+22IZIT+ipqeYN1b37fkNzv35QooQ99Yfy6KP2GhLyFBXly8Pjj8PChfDcc9a2cyfccAO0ahX9aiRfiaQ5itvhK4jii/+dnPwmNVW1enXVQYOiH/N//2dP6j/9lPXa/Pl27fXXM7b/61+qTZrsX1WsW6datqzq5ZfnTe60NNVTT1WtWlV1wwbV22+3z50zR1WTk1Vffll10iTVPXvy9gFhwFcQjuMcSvz6K2zcaG6k0TJokHkyPfNM1mtB+8Npp2VsHzgQVq2Cb7+187FjzR01EE+aa0Tgv/+F7dvhkkvg//7P5Dq51Hdm9Bg0yJYuDRqY0SLgjh4rXEE4jlMk2L7dbsAvvJB9v5QU+Pe/s09QN2eOvWZnoM5MtWoWoTxxYtYo6Zkz4ZhjoHbtjO19+0K5crbNtHmzBcJdeKG51uaVli1tW+mTT6BSxTQeSbsFTjwR/vnHIu4+/dQ039ix0Ly5uWO9/Xb2Fva8EmlpUdwO32IqvvjfyVFVfeUV204B1bvu2r9tE8qWLao9elifypXNsBuOiy5SrV8//BzZEdxK+u9/97ft2qVapozqiBGRP6t6ddV77rGxixbl7jPDsWVzmp7SYp2+fdjlqnFxqjfdpLptW8ZOf/2lev/9qo0aqXbpkufPIpstpkK/sefX4Qqi+OJ/J0dV9cwz7V539dV2ZxowIONW+8qVqq1amYfQ0KHWZ8KErPOkpanWravav3/e5Dj2WNWjj96vXGbMsM/6+OPw/adOteslSqj27p23z8zA33+r9u1rkx5/fHijSCgpKWb8yCPZKQjfYooh3bp149NPP83Q9sQTTzB06NCIY7p27UpCQgIAZ511Flu2bMnSZ/To0enxCJGYMmUKS5bsL8I3cuRIZgY3Uh2niPHPPxal3K8fPPssPPCARRj36AFbttge/3HHQWKi7bCMGwctWljfzPz+OyQl5W57KZRrrzUbxpdf2vnMmVCyZGR7xhlnWOqNtDS4++4cJt+zxyLuIuUumzbN9rI+/tjcoebOtbDv7IiLy7r3lU/EVEGISA8RWSYiK0QkrNlGRC4UkSUislhE3ghpv0xElgeOy2IpZ6zo378/kzKFWk6aNCliwrzMTJs2jSpVquTpszMriDFjxtC9e/c8zeU4sebdd8220K+fGWrvusuinOfONdtst25QuTJ8951tuYvANdfA999nzcEZvLHnxkAdykUXWW6mp5+2888/t6yrgcTJWShd2ozSV18NnTplurh9u+XxuOceE6hyZTNQ1K1rVuiJE+Hvv82f9dproWdPqFUL5s83P9kShfwMH2lpcaAHEAf8DhwBlAYWAi0z9WkK/AhUDZzXCrxWA1YGXqsG3lfN7vOK4hbTxo0btWbNmrp3715VVV21apU2bNhQ09LSdMiQIdqxY0dt2bKljhw5Mn3MKaecovPnz1dV1UaNGumGDRtUVfX+++/Xpk2baufOnbVfv3766KOPqqrq+PHjNT4+Xtu0aaPnnnuu7ty5U+fOnatVq1bVxo0ba9u2bXXFihV62WWX6eTJk1VVdebMmdquXTtt3bq1Dh48WPcE1vGNGjXSkSNHavv27bV169b666+/ZvlOq1at0pNOOknbt2+v7du317lz56Zfe+ihh7R169bapk0bvf3221VVdfny5XraaadpmzZttH379rpixYoscxb238kpfLp2VW3RIqvNYNYs1SpVVE85RfWffzJe27jRXEqHDMnYfumlqjVr5t7+EMrNN9tW1i+/qIqojh4dxaDUVNWlS80VdehQ1fbtzX4A9tqpk0XkPfus7Z/VqLHf6FK1qn3QLbeo7t6dd8HzAIVhgwBOAD4NOb8TuDNTn0eAK8OM7Q88F3L+HNA/u8/LSUEMH27/yPLzGD485x+/Z8+eOmXKFFVVffDBB/Xmm29WVVMeqqopKSl6yimn6MKFC1U1vIJISEjQ1q1b686dO3Xr1q165JFHpiuIf0L+19x999361FNPqapmUAih57t379YGDRrosmXLVFX1kksu0bFjx6Z/XnD8uHHj9IorrsjyfXbu3Km7A/+Af/vtNw3+7tOmTdMTTjhBdwashsHv16lTJ33vvfdUVXX37t3p10NxBXHwsGNH1ht5TiQmZn8T3rkz8s3+0ktVK1VSDSQLUFWzY5x3Xu5kyEBKii7/bKWCaoe6iQqqX7+yImN4c5Dly1X/9z/VXr3sJh+84VeqpNq9u1muP/sso4BBUlNVExJUH3hA9YILTBsWAtkpiFhmc60P/BlyvhY4LlOfZgAiMhdbcYxW1U8ijK2f+QNE5GrgaoDDDz883wTPT4LbTH369GHSpEm8+OKLALz99tuMHz+elJQUkpKSWLJkCW3atAk7x1dffUXfvn3TU273Dsn+9csvv3DPPfewZcsWduzYwRlnnJGtPMuWLaNJkyY0a9YMgMsuu4xx48Zx4403AnDuuecC0LFjR957770s4z0tuJOZlBTbhpk40XIaVakCf/wRfYWzoIdmpPTV4RLtBRkyBF591eorXHWVJbVbs8ZSa0dkxw7b49+82baAduyw1y1brIrQL79w1K5dnMF0Pk3qQUW20+myFnB9OTOEnHCCBVl88gmsXGlzNmliVYBOOMH6tGiR8w9QogR07GhHEaWw032XxLaZugINgDkicky0g1V1PDAeID4+Plsn4MLK9t2nTx9GjBjBDz/8wK5du+jYsSOrVq3iscceY/78+VStWpVBgwaxZ8+ePM0/aNAgpkyZQtu2bXn55Zf54osvDkjeYMrwSOnCPS24E+SPP+DJJ82YvG6dKYbjjrOUFPPm2b0yGiZNstpbLVrkXobjjzeb7rPPmoIIJroLa6DetcsMCw8/bFbxUCpWhMMOs7iCq66Ctm25dvNRfHozdO1WglKDX7LqQt9+axb0cuXMMDJihFmpjzoqtpV7ColYWkASgdBaTQ0CbaGsBaaqarKqrgJ+wxRGNGOLBRUrVqRbt25cfvnl6cbpbdu2UaFCBSpXrsz69euZPn16tnN06dKFKVOmsHv3brZv386HH36Yfm379u3UrVuX5ORkXg9JClOpUiW2b9+eZa7mzZuzevVqVqxYAVhW1lNy4e7hacGdIP37W9Tv8cebkXndOnjnHXsw/uST6OZYtcoMzVH6bWRBxFYRP/wACSeP4Muhk6hSaiet5z5nlXVUzXPoqaf2p0zt0MEs2UlJtnJITbXXxEQrGffEEzB4MD2HH8U558BVN1Ywg/Izz5hFfNs2K+324Ydw/fVmdD4IlQPEVkHMB5qKSBMRKQ30A6Zm6jMFWz0gIjWwLaeVwKfAv0SkqohUBf4VaCuW9O/fn4ULF6YriLZt29K+fXtatGjBgAED6Ny5c7bjO3TowEUXXUTbtm0588wzOfbYY9Ov3XfffRx33HF07tyZFiGPYP369ePRRx+lffv2GepFly1blgkTJnDBBRdwzDHHUKJECYYMGRL1d/G04EWfHTtinoGBv/+2h+l777XCO+eeaxXRqlWzVUQOzzzpBJ38Lrwwj4Js2sTARbdTnp08+3175nAyJ5WYS9x1QyzDXa1atv0zfLitDr76an8kcp06tnKI4CkUF2ffLUs9hwoVzHXpUCCScSI/DuAsbFXwO3B3oG0M0DvwXoDHgSXAz0C/kLGXAysCx+CcPqsoejE50eF/p/zllltUy5WzqONY8eqrZotNSMh67d//NqPz33/nPE+bNqonnJAHAZKTzThcrZpqiRJ6ZYuvtGzZNAXVRx9JM+Pxiy9atr5evVRnzjwwt6aDGArJSI2qTgOmZWobGfJegZsCR+axLwEvxVI+xzkY+fxz2L3b7LADBsTmM6ZNs9is9u2zXjvzTBg1ytz/Bw6MPMeSJVbUJ2yK7Z0791uc16yBtWv3H4mJVtpt506zAzzxBNfsa8MLgYV1l1PEbAJHHQWXX54v3/dQpbCN1I7j5CNbt+4PHHvnndgoiJQU26Xp0yf87kzHjlZr+ZNPslEQu3czafw+SpQ4jAuS34S7frEQ6N9/h9WrzUsolLg4K9bcoIEVhO7RwyLmzj4bRIgPfO7SpeGVlpM3DnoFoarIQWpAOhiwRaSTX3zzjdllW7WyG/TOnbZlnp/Mm2ceomeeGf56iRLm2PPpp0raj4so8e5kS6+6caMN3LQJ3buXSSyjKwnUuXmg5bJo3NgMyfHx9r5Ro/1HnTo5uo2+8IItLEqVyt/veyhzUCuIsmXLsnHjRqpXr+5KogiiqmzcuPGQdpVdudL8/594AnLwVYiKr76ye+1DD0GvXmYsPv/8A583lGnT7F59+ulhLqrCwoX02P4br2+4kB86XEF8iR/Ncn300ZbDompVvt/RmuXPNOPWG1Pght/h8MNN8AOgXTs7nPxDDpYnuPj4eA0muQuSnJzM2rVr8xxj4MSesmXL0qBBA0odoo99vXubt2R8vD2ZH+hzzEkn2RbQ119bup/u3S2ILD/p0MGcf4I1FwBTDJ9/bjmHvv+eDSVqUzvtL8b0XsA9LzSGmjUzzHHWWZZXadUqS0/kFB4iskBV48NdO6hXEKVKlaJJkyaFLYbjhGXaNFMOnTtbUrqgu2he2b3bcrwNG2YP4+ecY26ke/ZYpbRI7Nmz32C8aBEsW2bJ8sKtaJKS4Mcf4cEHQxrnzrU0pl9+CQ0bwv/+R80LL6TjWSWY/s+x3JNRNzB3rq1sHnrIlUORJ5J7U3E7wrm5Ok5B8NFHqs88k7sxe/aoHnWUarNmVpDm6KPtCJfuJ1q++MJcT6dOtfNPPsl4npk1a1Tj4/fnkwNzj61YUbV16/CyvPSS7q/bvGjR/uo9tWurPvVUhgIO995rNRI2bdo/Pi3N8pjVrm15m5zCB68H4TixITHRooBHj87duLFjrSzAU09Z1ob777caBK+9lndZgmkmgk/+3bpZ+ot33w3f//rr7TPvvNMqWS5bZgHFEybAL7/Ayy9nHTNtmjkTtUmcbiHU8+ZZ6oqVK61OZiBVC5ijUVqa1XkI8vnnttC46678N547MSCS5ihuh68gnMLgnHM0vZpYtE//f/6pWqGCjQ2SlmZP840aZayilhtOP131mGMytl16qaXLDmScT2fKFJM7kBQ4A2lpFrxWt27Gp/x9+1QPO0z1yi7LbNnRvr1qUlJEeZKTLcHp4MH75z3uONWGDfP+HZ38B19BOE7+8957MGWKOeekpcGGDdGNu/VWS//z+OP720TgP/+xmLDx43MvS0qKubiefHLG9vPOsySls2djPq+q7NxpdorWrS0DRWZE4LHHzN7wf/+3v/2bucq2bXDWnNttefLll+Z+GoGSJc3T6ZNPbAPro48s79LIkRkWGk5RJpLmKG6HryCcgmTzZnvCbt9e9a237Gn8xx9zHhe0E4walfVaWpoVzqlVK3z5gOyYN8/mnTQpY/vu3aoVK6bpVa3mWoeKFfW2mi9ZjYMB41Sfe86KLf/wg9U1Tk1NH3veebbSSUpS1ZQUva39Z1qSfbr1giuyLkkiMGGCfewPP6i2bat65JG2EnGKDhRGwaCCPlxBOAXJNdfYtlJCgurcwL13+vTsxyQn2xZQo0ZmmA7Ht9/aXA88kDt5/u//bFxiYqYLu3frRQ2/1pqs15SBl+rPAx/UkpKsl1eerFq6tKZbp4NHXJxqvXqqzZrpb03P0pIk6zW131Nt3VqPYaF2a7g8gxLJib/+smmPP1iumkkAACAASURBVN5eJ07M3fdyYk92CuKgdnN1nFgwZw489xzcfLOldwjWjElKyn7cJ5/Azz9bgZxy5cL3Of54i4145KFUhly8m2qHRyiEHEamI480A3I6W7fCOedw3p81eIvJzLniFUaNgsOqwsPLzoeqfeGvvzIeSUl27NpF0337GJo8nXGre9O39rf8TBseHUauckDXrWvBa999By1bWs1ppxgRSXMUt8NXEE5BsHu3avPmqo0b7zfg7txpT8f/+U/2Y5980voFyoxHZNE9b6mQqjdXn6D6xx85ypSaqlq9uiUuTScx0VKlliyp21+YpGXLmlstqL7wQo5TprNhgxmmK1e2sYsXRz82yB132Nh33839WCf24EZqx8kf/vMfcwd99tn9bprly1sxspxKXSQmWhmB6tWz6fTooxxz/0UMrjOdpzYO4Lf4ARa9lg1Ll1qaoy5dAg0JCVbObeVKmDaNildcRI8e5lZ74okweHDUX5caNcwldetWy4Zx9NHRjw1y44224gpUnnWKEa4gHCdKvv3WFMQll1gyulDq1IlOQdSrFyGdhqq599x2G1x0Ef+Z/y/KVohjxNbRlj9j5syI8wZTXpxcf6VV3jn2WNi3z7yMAgmTBg0yRfbMMxHr40Rk2DBo1sxyRuUlFUjt2nD11Qdt0bWDm0hLi+J2+BaTE0u2bLFtpcaNwxfi6dLFjuzo2lW1c+cwF9LSVIcPt32YK65ID6h49FFr+rjRUNWSJVVfeSXsvAP67NA65TZrmpQwt6N77w0r5IF4DyUne72dgxUKa4tJRHqIyDIRWSEid4S5PkhENojIT4HjypBrqSHtmUuVOk6BoQpDh1oq6TfeCJ8/qE6dnI3UiYlQv36mxrQ0uOoqePJJ24t5/vn0tNbBJ/cRpf7LvpNOhcsusz2iLl3SD+18EnM+2ESXvTOQ4cNsW2nMmLBCHkg+xJIlfQVwKBIzBSEiccA44EygJdBfRFqG6fqWqrYLHC+EtO8Oac9cFdZx8kRamqV70FwkMZ440TKijh5tW/vhqFs3+y0m1QgK4sEH4cUXLQvq449nuAuXLm0pOX5bEcd/e3xsblNly9rdOnCsSWvIWhpy8qjTrHOtWtF/McfJgVi6uXYCVqjqSgARmQT0wepPO06h8PzzMGSI5RSKVPAmlN9/h2uvtQjlO++M3K9OHctjFKlAz9atsGtXJgUxe7bZHQYMsKf+MI/oZ51lx5j/lOTi3x6jdu2M1+e8CnwHXc6plvOXcZxcEsstpvrAnyHnawNtmTlPRBaJyDsi0jCkvayIJIjIdyJyTrgPEJGrA30SNkSb58A5ZElNtRQSYPWacyI52e7dJUvaKiK7gmbBjBPr14e/nphor+kKIinJsvw1a2YuPtns34wda8rlrrv2t23YYMn0xo61hHytW+f8fRwntxS2F9OHQGNVbQPMAF4JudZIrYjFAOAJETky82BVHa+q8aoaXzNTQRLHycyUKebqWaOGKYictplGjbJkpc8/by6eYVGFBx+kzkTTPJG2mTIoiJQUUw7btlnh6IrZB8M1a2Y5kyZMgNtvt2yttWubu+rff1sy1dx6JjlONMTyn1UiELoiaBBoS0dVN6rq3sDpC0DHkGuJgdeVwBeAlyJ38owqPPKIRRuPHg2rV1s8QyT++QcefdTswtmW7Lz/frjrLup+bnm6k1bsDNvtr7/stX59TPN8+aX5nLZqFZX8995rSuGRR6zAz8iRsGABrF1rLqSOEwtiqSDmA01FpImIlAb6ARm8kUSkbshpb+DXQHtVESkTeF8D6IzbLpwD4KuvbDVw881w9tnWNn165P7vvmsP+jfemM2kjz1md+rLLqPOs/8GYN09/7OotUwEVxD1Fn1iwRRXXGHaJ0oqV96vEBYsMCXXoYN7FjmxJWYKQlVTgOuBT7Eb/9uqulhExohI0CtpmIgsFpGFwDBgUKD9aCAh0D4beEhVXUE4eeaRR6ws8qBB0KiR5QWaNi1y/0mToHlzaNs2Qof//c/ydl90Ebz4IjWuPIcSJZR1f6XBKadk8XlNXLmX6hX3UPaKgdCmDfz3v7n+DvXqhfGCcpxYEilAorgdHijnROLnny3gbMyY/W233GLJTMOl1U5MVBUJn5JbVS2ZEaj26ZMh+qxOHdUrz0q0YLUjj7Qc1y++qHrmmdpbpmobflJt0kR12bJ8/X6OcyDguZicQ5nHHrM0E9deu7/tzDMtG8WsWVn7v/222SyyZB794w8zTFx1ldXTfOutDNFndetCktSztBgbN9oe0BVXwK+/klirHfWOb2RW8mbNYvNFHSef8XTfTrFn8WJ4+mkzLN9yi6UiCrJ2rUU/Dx2aMUneSSeZ89C0aZZeO5RJkyxFdYt622DKLCuqPHMm/Pabdeje3crJZSqLlp6P6fjjYe5cc5U67TRo357EekK7VhS+36Dj5AJXEE6xJCUFPvzQtvJnz7Z7dfny9vTfu7fFnbVtaxks0tJgxIiM40uXtjx206bZaiFo7F21yspiPnzTejiytWmdChXMrjBkiA1q1SqsdbhOnZDEqy1b2oHFU6xf7/YDp/jhCsIpdrz/vsUF/PmnxSc89JDt5JQpA089ZVtK7dqZe+qnn1qC08aNs85z1lk215Il+71NJ02y1wtf72MRcjNnWhh16dI5ylWnjimCtLSMcQnr1pkScgXhFDd8wesUK1TN9bRCBQt8W7nSgsdq1IBKleDuu20VcO+9VsFt+3ZzNgpHjx72GurNNGliMieU/YHGe5aadjnttKiUA5iCSEmBTZsytmeJonacYoIrCKdYsXy52YqHD4c+fcKnv6hSxbaYVq2yUpftQ0Msd+2Cjz6CDRto0MA8ToMKYsm8HSxaUor+qROtT5s2uZKtbiCqJ3NWV1cQTnHFFYRTrJgxw167d8+5b40acNxxIQ1BbdGrlwUV9O7NWUcs5euvlW1/72HShe9RglQueOkss2LnkmA+pszpNlxBOMUVVxBOsWLGDLMnHJklM1c27N1rme46d7Y8FW+8ATfdBD/8wJlTriYlRZjR6W4mrTmeri03UOfiKLRPGLJTEKVLm8JynOKEKwin2JCSYh5Lp5+eixQTP/1kfq8PPmjZ7X7+2RLlPfwwrFnDCdNHUbnUTh5cewnLaUb/EXXyLF92CiJiqVHHKcK4gnCKDfPmWQLUQJnlyKha5yuuMOWwYYPZFF54AQ47bH+/uDhK9TiNf51TgQWp7ShVCs49N+/yVapkxvNwCsK3l5ziiCsIp9gwc6Y9hZ96aoQO27fDs89aBPNxx1mk81VXwS+/QM+eEecNFg464wyodoB1d8KVHv3rL1cQTvHEFYRTdElJsWR4t90G+/YxYwZ07JgxIhqwSkBjxpgb0dCh1vbMM3ZnfvrpMAMy0rOn2QfyI212ejR1gIilRh2nGOCBck7RZexYC40Gtn+xgO9+nMmtt2bayE9KgoEDzThxwQX7c23kYsO/Vi3bhcoP6tSxwLsg27ZZGdJ69fJnfscpSHwF4RRNfvvNai2ccw68/TZf/FKdlBTh9MO+399n5kwLmf7uOyu39vbb0KlToVqDM68g3MXVKc74CsIpeqSlwZVXWu6Mp5+GunWZ8WF3yk/czYl3doEdt1qE3H33wdFHW0rWKCuzxZq6dWHzZvOmLVvWFYRTvHEF4RQ9nn3WSsC9+GJ6ePKM+VXp0j2VModfAg88YP0GDbLCPRUqFJ6smQi6uq5fb4WJXEE4xZmYbjGJSA8RWSYiK0TkjjDXB4nIBhH5KXBcGXLtMhFZHjiir83oFG/WrLHkSqefbnELWMrupUvh9B5x5qo6ebJtJ02YUKSUA2SNhUgvNeo2CKcYErMVhIjEAeOA04G1wHwRmapZS4e+parXZxpbDRgFxAMKLAiM3RwreZ0igCpcc429jh+fbksIptdIj384//zCkS8KwimIatWgXLnCk8lx8kosVxCdgBWqulJV9wGTgD5Rjj0DmKGqmwJKYQbQI0ZyOvnExo2wYMEBTPDqq5ZB9cEHM+TnnjEDateG1q0PWMSYE0zYF6ogfHvJKa7EUkHUB/4MOV8baMvMeSKySETeEZGGuRkrIleLSIKIJGzILz9FJ8/cc4/Fp333XR4Gz5plKVo7d4brrktvTkszZ6Xu3YtHqoqaNU3OYLCcKwinOFPYbq4fAo1VtQ22SnglN4NVdbyqxqtqfM2aNWMioBM9M2dazNrFF8OOHVEOSkszb6Tu3W2j/rXXMlTbWbTIYhRyTK9RRChVyoLufAXhHAzEUkEkAg1DzhsE2tJR1Y2qujdw+gLQMdqxTtHizz9hxQozD6xcaUV9cmTDBivrNnIkDBhg+ZOaNMnQJTfpvYsKwVgILzXqFHdiqSDmA01FpImIlAb6AVNDO4hI3ZDT3sCvgfefAv8SkaoiUhX4V6DNKaLMnm2v99wDd9xhHqrvv5/NgG++sdoMX3wBzz1nK4eKFbN0mzHDSjsXp5ts3bqmILzUqFPciZkXk6qmiMj12I09DnhJVReLyBggQVWnAsNEpDeQAmwCBgXGbhKR+zAlAzBGVTdl+RCnyDBrlqU8OuYYi1377DPLk3f88VC36h5Luz1//v5j2TJbLXzzjSXXC0NCAnz+eeSSoUWVOnXMLddjIJziTkwD5VR1GjAtU9vIkPd3AndGGPsS8FIs5XPyB1VbQXTrZuaD0qVh4kTo0EEZfPIKpv1xDCWSAzuJtWtbrqSLLzZjdJUqYedMTjYFU7u2rUiKE8EtJo+BcIo7HkntHDArV1qd6Ntv39/Woso6Hm/4JkN/G8G49s9wwz2VTTE0aBCVO9LYsbboeOediDqkyFKnDuzbB4sX27mvIJziiisI54CZNcte0+s0zJoFAwZwzdZtfNT2fG5dMpg21eGUhhGnyMDvv8OoUdCnz4EV8CksgsFyCxbs92pynOJIYbu5OkWIlBQ48UR4993cjZs92wyzzY9KhX//21yOqlZF5s/j5ZkNOeIIq7kwd27OcwWDqUuVgnHjikfsQ2aCwXILFtj2Ugn/X+YUU/yfrpPOb7/Bt9/C889HP0bVFgynngpy150werTVZ5g/H1q3pkYNMzTXq2eV2+bNy36+V1+1/g8/XHy3ZoIrCI+BcIo7USkIEXlPRHqKiCuUg5iFC+119myr3hkNv/5qvv7dWm+AJ5+0DKuvvprBZbVuXVMiNWvCv/4FP/wQfq6//4abbrJg6muuObDvUpgEFQS4gnCKN9He8J8GBgDLReQhEWkeQ5mcQiKoIPbts6joaEi3P3z7gNVouP/+sPtCDRpY38qVLSp60SJrT021bK1z55pS2L7d8vQV522ZypWtlAW4gnCKN1H9N1TVmao6EOgArAZmisg3IjJYRErFUkCn4Fi0yILSqlSBjz6Kbszs2dC43l6aTH0SRozI9o7YqJH1L1cOunSBI46wojoNG8JJJ8GUKWacbtkyn75QISGy3w7hCsIpzkTtxSQi1YGLgUuAH4HXgZOAy4CusRDOKVgWLoTTToM2beDjjy1NUnZP8mlpMHu20rfsLHPVue22HD/jiCNMSdx+uymHiy4yxdGokV1rfpCsTevUgdWrXUE4xZuoFISIvA80B14DeqlqIFclb4lIQqyEcwqOf/6Bv/6Ctm3t5jZpkkUyd+oUeczChbB5s9CN1+HJe21vJQqaNoX33ssnwYsoQTuEKwinOBPtCuIpVZ0d7oKqxuejPE4hEbQ/tGkDHTvayuHDD7NXELM/TwNK0O3wlTDEg95DcQXhHAxEawpsKSLp8ayBJHrXxkgmpxAIKoi2ba0CWufOOdshZk1MpDlLqf/ojZZfw0mnSRMzVHuaDac4E62CuEpVtwRPAlXeroqNSE5hsHChPfXWqmXnZ59tqS7Wrg3fP2X7buYsqsKpNX+BCy4oOEGLCdddZzEfXmrUKc5EqyDiRPb7LgbqTfsj40HEokW2egjSq5e9RlpFLLj9bbZrJU697ujiGe4cYypUsO06xynORKsgPsEM0qeJyGnAm4E25yAgORmWLMmoIFq0MK+isApi7lxmPbccgK7XtSoYIR3HKXCiNVLfDlwDDA2cz8AqwDkHAUuXWnBcqIIQsVXEc8/Brl1QvnzgQmIia8+5nmdKfEz71inUqOH5Hh3nYCXaQLk0VX1GVc8PHM+pamqshXMKhlADdShnnw179lhuJAD27mVj78H8a+ObbC1bmxdfduXgOAcz0eZiaioi74jIEhFZGTyiGNdDRJaJyAoRiVj2RUTOExEVkfjAeWMR2S0iPwWOZ6P/Sk5uWbjQnJCaNcvY3qULVKoU2GZSZcfVN9HzhzGsLNmUqR/F0b59oYjrOE4BEe0j4ARgFDAW6AYMJgflEjBkjwNOB9YC80VkqqouydSvEjAc+D7TFL+rarso5XMOgIULoVUrS7EdSunScMYZpiD2/nc8577ah/nSifcml+CUUwpHVsdxCo5ojdTlVPVzQFR1jaqOBnrmMKYTsEJVV6rqPmAS0CdMv/uAh4E9Ucri5DPpHkw7dpjrTYsW0Ls33HorZ1f6kr/+gm7D2zCDf/HC81bIx3Gcg59oFcTeQKrv5SJyvYj0BSrmMKY+8GfI+dpAWzoi0gFoqKofhxnfRER+FJEvReTkcB8gIleLSIKIJGzYsCHKr+KEsn69HW3bYum6f/7ZcmGsXAn//S9nTTgfIY1vOYFHx+xm8BXFOM2q4zi5ItotpuFAeWAY9sTfDUvSl2cCCudxYFCYy0nA4aq6UUQ6AlNEpJWqbgvtpKrjgfEA8fHxeiDyHKqkG6iP2A6XPmorhw8+sMbUVGr+8Qc33/YHNVrW4pZ7y0eeyHGcg44cFUTAlnCRqt4C7MDsD9GQCIRWIW4QaAtSCWgNfBGIwasDTBWR3qqaAOwFUNUFIvI70AzwxID5TLqCmP0EbNsG9923/2JcHDRpwqOTC0c2x3EKlxz3CwLurCflYe75QFMRaSIipYF+wNSQebeqag1VbayqjYHvgN6qmiAiNQOKCRE5AmgK5Og15eSehQuhQb1Uqo1/yHJve/iv4zgBot1i+lFEpgKTgZ3BRlWNmLRZVVNE5HrgUyAOeElVF4vIGCBBVadGGgt0AcaISDKQBgxR1U1RyurkgoULoW3ppbB3L/z734UtjuM4RYhoFURZYCNwakibAtlm9VfVacC0TG0jI/TtGvL+XeDdKGVz8sjevbB0qdIr7SMYPChrIITjOIc0USkIVY3W7uAUI379FVJShLZxi2Dkg4UtjuM4RYxoK8pNwFYMGVDVy/NdIqfAWPjpOqAObfsdDYcfXtjiOI5TxIh2iyk0p2dZoC/wV/6L4xQkCyf8QDm60vThKwtbFMdxiiDRbjFlsAeIyJvA1zGRyCkYli9n4bIytK67kbj6DXPu7zjOIUdew2KbArXyUxCnYNHXJrKQtrTtVq2wRXEcp4gSrQ1iOxltEOuwGhFOMUIV1qyBed8r3zzVmI3UoO0JhS2V4zhFlWi3mCrFWhAndvzxBwwbBt98A5aySihDf05quo6ePesUtniO4xRRoq0H0VdEKoecVxGRc2InlpOf3HADzJgBPXvC00/Dgn6Psr10Db6aX44mTQpbOsdxiirRejGNUtX3gyequkVERgFTYiOWk1/MnAlTp8KDD8IddwApKTD6MejVAypXznG84ziHLtEaqcP183qTRZyUFBgxApo0gRtvDDR+/jn8/TcMHFiosjmOU/SJ9iafICKPYxXiAK4DFsRGJCe/ePFF+OUXeOcdKFs20PjGG7ZyOPPMQpXNcZyiT7QriBuAfcBbWGW4PZiScIooW7bAPfdYXelzzw007toF770H558fojEcx3HCE60X007gjhjL4uQj998PGzfC2LFg5TaADz+0sqK+veQ4ThRE68U0Q0SqhJxXFZFPYyeWcyAsXw5PPQWDB0OHDiEXXn8d6tWzZYXjOE4ORGuDqKGqW4InqrpZRDySupCZMgUmT4aOHaFTJ1MG5cvDrbdCmTLwwAMhnTduhOnTYfhwqxTnOI6TA9EqiDQROVxV/wAQkcaEye7qFCzPP2/3/DfesPO4OGjRAhYvNrfWOqExcO+8Y25Nvr3kOE6URGukvhv4WkReE5GJwJfAnTkNEpEeIrJMRFaISEQbhoicJyIqIvEhbXcGxi0TkTOilPOQYt06c0ZKSrJYhzvvhPr14fTTQ9xag7z+Ohx9NLRrVyiyOo5T/IjWSP1J4OZ9NfAjFiC3O7sxgZrS44DTgbXAfBGZqqpLMvWrBAwHvg9pa4nVsG4F1ANmikizQH1sJ0BSErRvbyuFXr3sCMuvv8JXX8F994VYrB3HcbInWiP1lcDnwM3ALcBrwOgchnUCVqjqSlXdh7nH9gnT7z7gYcx1NkgfYJKq7lXVVcCKwHxOgNRUWL8e6tbNptPOnTBqlBkpKlSASy4pMPkcxyn+RLvFNBw4Flijqt2A9sCW7IdQH/gz5HxtoC0dEekANFTVj3M7NjD+ahFJEJGEDZaF7pBhwwZIS4ugINLSbEupeXMYMwZ69zbDRKNGBS6n4zjFl2gVxB5V3QMgImVUdSnQ/EA+WERKAI9jq5I8oarjVTVeVeNr1qx5IOIUO5KS7DWLgli2DE48ES6+2Paevv4aJk1y5eA4Tq6J1otpbSAOYgowQ0Q2A2tyGJMIhJYqaxBoC1IJaA18IbYvXgeYKiK9oxh7yBNUEBk8lf7+G844w7aWJkyASy+FEnmtCeU4zqFOtEbqvoG3o0VkNlAZ+CSHYfOBpiLSBLu59wMGhMy5FagRPBeRL4BbVDVBRHYDbwTyP9XDKtjNi+obHSJkWUHs2QN9+5qSmDMH4uMjjnUcx4mGXGdkVdUvo+yXIiLXA58CccBLqrpYRMYACao6NZuxi0XkbWAJkAJc5x5MGcmwglCFq66yikCTJ7tycBwnX4hpym5VnQZMy9Q2MkLfrpnOHwAeCNfXsRiIqlUDOff+8yBMnGhurOefX9iiOY5zkOAb1MWUpKTA9tJ778Hdd1uE9N13F7ZYjuMcRLiCKKYkJUHditsstuGEE+CFFzwIznGcfMUVRDElKUmpu+JrqFYN3n/f6zs4jpPveNnQYogqJCWmUTf5F3jwXqhdu7BFchznIMRXEMWQLVtgb3IcdSrusFgHx3GcGOAKohiS9MUyAOqe1cG3lhzHiRmuIIohSU+/D0Ddi08rZEkcxzmYcQVR3PjjD9bNsozpdZtVKmRhHMc5mHEFUdx44gmSsARM2ab6dhzHOUBcQRQnNm+G8eNJat6N8uWhki8gHMeJIe7mWpx45hnYuZOkxsdTd5/HxTmOE1t8BVFc2LMHnnwSevQgaXdV315yHCfmuIIoIDZtghEjYMeOPE7w6quWyvu220hKylQHwnEcJwa4giggPvoInnjCsmLkiaeestrSXbvuT9TnOI4TQ1xBFBDLLLaNjz7Kw+AlS6ym9ODB7NotbNvmCsJxnNjjCqKACCqITz+F5ORcDp482SzS553HunXW5ArCcZxYE1MFISI9RGSZiKwQkTvCXB8iIj+LyE8i8rWItAy0NxaR3YH2n0Tk2VjKWRAsWwYVKsDWrVb4LVdMngwnnwx16mQtNeo4jhMjYqYgRCQOGAecCbQE+gcVQAhvqOoxqtoOeAR4POTa76raLnAMiZWcBUFqKixfDhdfDKVKwccf52Lwr7/a9tIFFwBhalE7juPEiFiuIDoBK1R1paruAyYBfUI7qOq2kNMKgMZQnkLjjz9g714rFd2lSy4VRMj2EriCcByn4IilgqgP/BlyvjbQlgERuU5EfsdWEMNCLjURkR9F5EsROTmGcsacoP2heXPo2dNszqtXRzl48mQ46aR0jZCUBCVLQvXqMRHVcRwnnUI3UqvqOFU9ErgduCfQnAQcrqrtgZuAN0TksMxjReRqEUkQkYQNGzYUnNC5JLOCgChXEUuXwi+/wPnnpzclJVl9oBKF/pdzHOdgJ5a3mUSgYch5g0BbJCYB5wCo6l5V3Rh4vwD4HWiWeYCqjlfVeFWNr1mzZr4Jnt8sWwZVqkDNmtCsGRx1VJQKYvJkew1sLwEeA+E4ToERSwUxH2gqIk1EpDTQD5ga2kFEmoac9gSWB9prBozciMgRQFNgZQxljSnLltnqIZg7qWdPmD0bdu3KYeDkydC5M9TfvzPnCsJxnIIiZgpCVVOA64FPgV+Bt1V1sYiMEZHegW7Xi8hiEfkJ20q6LNDeBVgUaH8HGKKqm2Ila6wJKoggPXtaaqVZs3IY9PPP6d5LQdatcwXhOE7BENNsrqo6DZiWqW1kyPvhEca9C7wbS9kKiu3bITExo4Lo0sViIj7+GM4+O8LAd96x15DtpZQU2LDBFYTjOAWDmzpjzG+/2WuogihTBk4/3RSERnLsnTwZTjwRGjRIb1q/3vq7gnAcpyBwBRFjgh5MLVpkbO/ZE/7803aRsrB8OSxcmGV7yWMgHMcpSFxBxJhly8wl9aijMrafdZa9hvVmCuO9BPsVhKf6dhynIHAFEWOWLYPGjW1bKZR69aBDhzAKQhXeeguOPx4aNsxwyVcQjuMUJK4gYkxmD6ZQevaEb7+FjRtDGp94AhYtgquuytI/qCBq185/OR3HcTLjCiKGpKWZkTo7BZGWZinAAZg3D26/Hfr2hcGDs/RPSoIaNaB06djJ7DiOE8QVRAxJTLRguEgK4thjoVYt+PBDYMsWuOgiC4p78cX9UXUheAyE4zgFiSuIGBKagwmwtK4hfq0lStgqYvp0JXnQVbB2LUyaBFWrhp3Po6gdxylIXEHEkAwKYvJkaNQIjjsOpk5NVxS9esHWrcLXH/wDDz1k1yPgCsJxnILEFUQMWbYMKlaEunUU7r8fDj8c/vkH+vSBdu3grbc4vWoCpdnLh02Gw003RZxL1beYHMcpWFxBHCCpqbBjR/hr6Un6pk8zz6T77jOr9auvb4cKgAAADg1JREFUwr590K8fFU87jlPLfMOH9ELJancIsnGj1bL2GAjHcQoKVxAHwIoV0L49tGoFu3dnvZ7u4vrgg7Z66N/fqv1cconVeXj7bejRg97DGrNiVVz6llQ4PAbCcZyCxhVEHvnoIyshunq12Z6fey7j9d27rb152TUwdy7ccosVpA4SF2epND7+mLNvaAKYaSISriAcxyloXEHkkrQ0GDXKjMtHHGEpk0491ezLofUdli83u0HzH960SkFXXBFxzoYNzSTx4YeRP9cVhOM4BY0riFywaZOl5x4zBgYNsoVBkyamMNavz7iKSPdg+mkSDB8O5ctnO3evXvDNN5miqkNwBeE4TkHjCiIX9O8PM2fCM8/ASy9BuXLW3qWLrSIefnj/KiKoIJpVTILrrstx7l69bHUybVr46+vWQaVKVkfCcRynIHAFESUbNphyuP12GDIka6Dz6NG2inj2WTtflrCNw1lD+WsHWUHqHOjY0TyUIm0zeQyE4zgFTUwVhIj0EJFlIrJCRO4Ic32IiPwsIj+JyNci0jLk2p2BcctE5IxYyhkNH31kT/h9+4a/fvLJcNpp+1cRy77ZSHNZDjfeGNX8JUrY9tUnn5gHbCiqsGaNu7g6jlOwxExBiEgcMA44E2gJ9A9VAAHeUNVjVLUd8AjweGBsS6Af0AroATwdmK/Q+OADMya3bx+5z+jR8Pff8MxDW1m6oTrNW8bl6rG/Vy8rUTpnzv621FS44Qb4/nvo1i3v8juO4+SWWK4gOgErVHWlqu4DJgF9Qjuo6raQ0wpAMFFRH2CSqu5V1VXAisB8hcKuXfDZZ9C7d9gceumcdBJ0766MebAk2zmM5ue1ztXndO8OZcvu32bau9fsHuPGwa23wsiR2Y93HMfJT2KpIOoDf4acrw20ZUBErhOR37EVxLBcjr1aRBJEJGHDhg35JnhmZs60uIZzzsm57+gmr7ItxSzJzU+qmavPKV/etqk+/BC2bbOqc5Mnw2OPwSOP2DaU4zhOQVHotxxVHaeqRwK3A/fkcux4VY1X1fiaNXN3M84NU6ZA5cpwyik5dPz4Yzq/MJjT61ih6UhpvrOjd29YtcqM1nPmwGuvwc03534ex3GcA6VkDOdOBEJrZjYItEViEvBMHsfGjNRUM1CfdVbGQOgsLF8OAwdC27aMe+Uo3vk4S8XQqDj7bHtNSrKVRI8eeRLbcRzngImlgpgPNBWRJtjNvR8wILSDiDRV1eWB055A8P1U4A0ReRyoBzQF5sVQ1oh8+625uPbpk02n7dtt/6lkSXj/fZo2LsedbfL2efXqwRtvwNFHW3S14zhOYREzBaGqKSJyPfApEAe8pKqLRWQMkKCqU4HrRaQ7kAxsBi4LjF0sIm8DS4AU4DpVTY2VrNkxZYqtHM48M0KHtDS47DKLjPvsM2jc+IA/s3//A57CcRzngBENqXBWnImPj9eEhIR8nVMVmjWDI4+0+ISwPPww3HEHPP44jBiRr5/vOI4Ta0RkgarGh7tW6Ebqosyvv1pK74jbS7/8AvfeC+efH3VAnOM4TnHBFUQ2fPCBvfbuHeZicrJl7KtSBZ5+OvsACcdxnGJILI3UxZ4pU+DYY6F+lggM4NFHYcECC1SIoYut4zhOYeEriAj89RfMmxdhe+mXXyyvxoUX2vaS4zjOQYgriAgE011kURApKfu3lv73v4IWy3Ecp8DwLaYIfPCBVYxr1SrThUce8a0lx3EOCXwFEYY334Tp06Ffv0y25+DW0gUX+NaS4zgHPa4gMjFnju0gdemSKXuqKgwdakmZxo0rLPEcx3EKDN9iCmHpUsuY0aQJvP8+lCkTcnH2bPj6a1MOvrXkOM4hgK8gAqxfvz8h3/TpUK1apg733WfFfy6/vFDkcxzHKWh8BYEVBOrdG9atgy+/tBVEBr7+Gr74AsaOtYo+juM4hwCHvIJITYUBA2D+fNtWOvbYMJ3uuw9q1YKrry5w+RzHcQqLQ36LaeVKM0w/+WSEoLh58yxL6803W8k3x3GcQ4RDfgXRtKkZp2vVitDhvvvMIDF0aIHK5TiOU9gc8isIyEY5/PijlZMbMQIqVSpQmRzHcQobVxDZ8cADFvdwww2FLYnjOE6BE1MFISI9RGSZiKwQkTvCXL9JRJaIyCIR+VxEGoVcSxWRnwLH1FjKGZbFi+Hdd2HYMFMSjuM4hxgxs0GISBwwDjgdWAvMF5GpqrokpNuPQLyq7hKRocAjwEWBa7tVtXCqMqelwahRULGiFwJyHOeQJZYriE7ACtX/b+9uY+Sq6jiOf3+2tkBraLGVlG7TFihCTcq2bhAsGgRtKjENIRiRhxBTwpuaQGLQNvgQeYPGROAF0UJFMTZCClSbJoCw1iYE+rClC/TBCrbV7gbcNQGVGqtt/744Z2F2vY2zO7vcvTO/TzKZe87cnT3/7Jn9zz333nPiYET8G3gUGHSdUERsiYh/5uI2oG0M21Of3l5YtiwdPdx5Z8Edc2ZmrWEsE8Rs4EhNuSfXncpK4Kma8mmSuiRtk3RN0Q9Iui3v09Xf3994izduhEWL4MUX4aGH0nKiZmYtalycpJZ0E9AB/KCmem5eSPsG4D5J5w39uYh4MCI6IqJjZiPzIx09mm6Cu/badBv17t1w661eRtTMWtpYJoheYE5NuS3XDSLps8BdwIqIODZQHxG9+fkg8Dtg8Zi08tAhWLIE1q2D1avhhRfgggvG5FeZmVXJWCaIncACSfMlTQKuBwZdjSRpMbCWlBz6auqnS5qct2cAS4Hak9uj55xzUkLo7IR77oFJk8bk15iZVc2YXcUUEcclfRV4BpgAPBwReyXdDXRFxCbSkNJUYIPScM6fI2IFcBGwVtJJUhL73pCrn0bP5MnvrS9qZmbvUkSU3YZR0dHREV1dXWU3w8ysUiTtyud7/8e4OEltZmbjjxOEmZkVcoIwM7NCThBmZlbICcLMzAo5QZiZWSEnCDMzK9Q090FI6gf+1MBbzAD+OkrNKVszxQLNFU8zxQKOZzyrN5a5EVE4mV3TJIhGSeo61c0iVdNMsUBzxdNMsYDjGc9GIxYPMZmZWSEnCDMzK+QE8Z4Hy27AKGqmWKC54mmmWMDxjGcNx+JzEGZmVshHEGZmVsgJwszMCrV8gpC0XNIBSa9LWl12e4ZL0sOS+iTtqak7S9Kzkl7Lz9PLbGO9JM2RtEXSPkl7Jd2e66saz2mSdkh6Ocfz3Vw/X9L23OceyysuVoKkCZJ2S9qcy1WO5bCkVyV1S+rKdZXsawCSpkl6XNLvJe2XdFmj8bR0gpA0AXgA+DywEPiypIXltmrYfgYsH1K3GuiMiAVAZy5XwXHgaxGxELgUWJX/HlWN5xhwZURcDLQDyyVdCnwfuDcizgfeAlaW2Mbhuh3YX1OuciwAn4mI9pr7Bara1wDuB56OiAuBi0l/p8biiYiWfQCXAc/UlNcAa8pu1wjimAfsqSkfAGbl7VnAgbLbOMK4fg18rhniAc4AXgI+Qbq7dWKuH9QHx/MDaMv/ZK4ENgOqaiy5vYeBGUPqKtnXgDOBQ+QLj0YrnpY+ggBmA0dqyj25rurOjog38vabwNllNmYkJM0DFgPbqXA8eUimG+gDngX+CLwdEcfzLlXqc/cBXwdO5vKHqW4sAAH8RtIuSbfluqr2tflAP/DTPAS4TtIUGoyn1RNE04v01aFS1zJLmgo8AdwREX+vfa1q8UTEiYhoJ337vgS4sOQmjYikLwB9EbGr7LaMossjYglpiHmVpE/XvlixvjYRWAL8KCIWA0cZMpw0knhaPUH0AnNqym25rur+ImkWQH7uK7k9dZP0QVJyWB8RT+bqysYzICLeBraQhmGmSZqYX6pKn1sKrJB0GHiUNMx0P9WMBYCI6M3PfcBGUgKval/rAXoiYnsuP05KGA3F0+oJYiewIF+JMQm4HthUcptGwybglrx9C2ksf9yTJOAnwP6I+GHNS1WNZ6akaXn7dNL5lP2kRHFd3q0S8UTEmohoi4h5pM/JbyPiRioYC4CkKZI+NLANLAP2UNG+FhFvAkckfTRXXQXso9F4yj65UvYDuBr4A2ls+K6y2zOC9v8SeAP4D+lbxErS2HAn8BrwHHBW2e2sM5bLSYfArwDd+XF1heNZBOzO8ewBvp3rzwV2AK8DG4DJZbd1mHFdAWyuciy53S/nx96Bz35V+1puezvQlfvbr4DpjcbjqTbMzKxQqw8xmZnZKThBmJlZIScIMzMr5ARhZmaFnCDMzKyQE4TZOCDpioEZUs3GCycIMzMr5ARhNgySbsprPHRLWpsn43tH0r15zYdOSTPzvu2Stkl6RdLGgbn4JZ0v6bm8TsRLks7Lbz+1Zj7/9fnOcrPSOEGY1UnSRcCXgKWRJuA7AdwITAG6IuJjwFbgO/lHfg58IyIWAa/W1K8HHoi0TsQnSXfCQ5q99g7S2iTnkuY/MivNxP+/i5llVwEfB3bmL/enkyY/Owk8lvf5BfCkpDOBaRGxNdc/AmzI8//MjoiNABHxL4D8fjsioieXu0nrfDw/9mGZFXOCMKufgEciYs2gSulbQ/Yb6fw1x2q2T+DPp5XMQ0xm9esErpP0EXh3/eK5pM/RwIymNwDPR8TfgLckfSrX3wxsjYh/AD2SrsnvMVnSGe9rFGZ18jcUszpFxD5J3yStQvYB0gy6q0iLs1ySX+sjnaeANL3yj3MCOAh8JdffDKyVdHd+jy++j2GY1c2zuZo1SNI7ETG17HaYjTYPMZmZWSEfQZiZWSEfQZiZWSEnCDMzK+QEYWZmhZwgzMyskBOEmZkV+i/616DD/PsQsAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_LxatO5J-pp",
        "outputId": "777ae223-d6e9-44d1-ebc9-a920bd74ee1c"
      },
      "source": [
        "testloss = model.evaluate(xtest, ytest) \n",
        "print(\"Test Loss \" + str(testloss[0]))\n",
        "print(\"Test Acc: \" + str(testloss[1]))\n",
        "trainloss = model.evaluate(xtrain, ytrain) \n",
        "print(\"Train Loss \" + str(trainloss[0]))\n",
        "print(\"Train Acc: \" + str(trainloss[1]))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113/113 [==============================] - 4s 36ms/step - loss: 1.0377 - accuracy: 0.6172\n",
            "Test Loss 1.0377365350723267\n",
            "Test Acc: 0.6171635389328003\n",
            "1010/1010 [==============================] - 37s 37ms/step - loss: 1.0073 - accuracy: 0.6203\n",
            "Train Loss 1.0073107481002808\n",
            "Train Acc: 0.6202861070632935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swoRERVdKQ1-",
        "outputId": "26dfc725-4097-4bb8-e642-3170dcbc81d9"
      },
      "source": [
        "testlosz = model.evaluate(x_val, y_val) \n",
        "print(\"Test Loss \" + str(testlosz[0]))\n",
        "print(\"Test Acc: \" + str(testlosz[1]))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101/101 [==============================] - 4s 37ms/step - loss: 0.9617 - accuracy: 0.6368\n",
            "Test Loss 0.9617406725883484\n",
            "Test Acc: 0.6368421316146851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdU7uU3PYCnA",
        "outputId": "b35774a9-035c-4bd6-b060-209e5e030be1"
      },
      "source": [
        "print (x_val.shape)\n",
        "print (y_val.shape)\n",
        "print (xtest.shape)\n",
        "print (ytest.shape)\n",
        "print (xtrain.shape)\n",
        "print (y_train.shape)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3230, 48, 48, 1)\n",
            "(3230,)\n",
            "(3589, 48, 48, 1)\n",
            "(3589,)\n",
            "(32298, 48, 48, 1)\n",
            "(29068,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J11OOgMKYHJV",
        "outputId": "1df06400-a377-4fbd-f088-71df2c489a0f"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "y_pred1 = model.predict(xtest)\n",
        "y_pred = np.argmax(y_pred1, axis=1)\n",
        "\n",
        "# Print f1, precision, and recall scores\n",
        "print(\"precision_score:\",precision_score(ytest, y_pred , average=\"macro\"))\n",
        "print(\"recall_score:\",recall_score(ytest, y_pred , average=\"macro\"))\n",
        "print(\"f1_score\",f1_score(ytest, y_pred , average=\"macro\"))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision_score: 0.566893219099881\n",
            "recall_score: 0.5194167319880453\n",
            "f1_score 0.518644396784863\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvXSq92Spf6f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqXhenHGpggc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}